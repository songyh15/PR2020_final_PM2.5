{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def data_generate(data_pm25_filled):\n",
    "    data = []\n",
    "    label = []\n",
    "    data_pm25_filled_array = data_pm25_filled.iloc[:,3:].values\n",
    "    for i in range(data_pm25_filled_array.shape[0] -12 -6):\n",
    "        data_now = data_pm25_filled_array[i:i+12,:]\n",
    "        label_now = data_pm25_filled_array[i+12:i+18,:]\n",
    "        data.append(data_now)\n",
    "        label.append(label_now)\n",
    "    data = np.array(data)\n",
    "    label = np.array(label)\n",
    "    return data, label\n",
    "\n",
    "def Evaluation(label, predict):\n",
    "    MAE = np.mean(np.abs(label - predict))\n",
    "    RMSE = np.power(np.mean(np.power(label - predict,2)) ,0.5)\n",
    "\n",
    "    label_grade = label\n",
    "    label_grade[label_grade < 35] = 1\n",
    "    label_grade[label_grade > 250] = 6\n",
    "    label_grade[label_grade > 150] = 5\n",
    "    label_grade[label_grade > 115] = 4\n",
    "    label_grade[label_grade > 75] = 3\n",
    "    label_grade[label_grade > 35] = 2\n",
    "    \n",
    "    predict_grade = predict\n",
    "    predict_grade[predict_grade < 35] = 1\n",
    "    predict_grade[predict_grade > 250] = 6\n",
    "    predict_grade[predict_grade > 150] = 5\n",
    "    predict_grade[predict_grade > 115] = 4\n",
    "    predict_grade[predict_grade > 75] = 3\n",
    "    predict_grade[predict_grade > 35] = 2\n",
    "    \n",
    "    res = np.zeros(label_grade.shape)\n",
    "    res[label_grade == predict_grade] = 1\n",
    "    num_cor = res.sum()\n",
    "    num_all = res.shape[0] * res.shape[1]\n",
    "    prec = num_cor/num_all\n",
    "    return MAE,RMSE,prec\n",
    "\n",
    "# 读取数据\n",
    "# 注: 20141231读取不了, 删了; 20151230,1231是空文件, 删了\n",
    "\n",
    "# data_folder = os.walk(r\"data\")  \n",
    "# for path,dir_list,file_list in data_folder:  \n",
    "#     for file_name in file_list:  \n",
    "#         path_now = os.path.join(path, file_name)\n",
    "#         if file_name == \"beijing_all_20150101.csv\" :\n",
    "#             data_all = pd.read_csv(path_now)\n",
    "#             print(path_now)\n",
    "#         elif file_name[:11] == \"beijing_all\" :\n",
    "#             data_now = pd.read_csv(path_now)\n",
    "#             data_all = pd.concat([data_all, data_now], axis=0)\n",
    "#             print(path_now)\n",
    "# data_all.to_csv(\"data_all.csv\")\n",
    "         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv(\"data_all.csv\")\n",
    "# 选取pm2.5数据\n",
    "data_all_pm25 = data_all[data_all['type']=='PM2.5']\n",
    "# 删去无用的前三列\n",
    "data_all_pm25 = data_all_pm25.iloc[:,1:]\n",
    "# \"就近\"填充缺失数据\n",
    "data_all_pm25_filled = data_all_pm25.fillna(method='ffill')\n",
    "data_all_pm25_filled = data_all_pm25_filled.fillna(method='bfill')\n",
    "# 划分数据集\n",
    "data_train_pm25_filled = data_all_pm25_filled[data_all_pm25_filled['date'] < 20200000]\n",
    "data_train_pm25_filled = data_train_pm25_filled[data_train_pm25_filled['date'] > 20150000]\n",
    "data_val_pm25_filled = data_all_pm25_filled[data_all_pm25_filled['date'] > 20200000]\n",
    "data_test_pm25_filled = data_all_pm25_filled[data_all_pm25_filled['date'] < 20150000]\n",
    "# 制作时序数据集\n",
    "train_data,train_label = data_generate(data_train_pm25_filled)\n",
    "val_data,val_label = data_generate(data_val_pm25_filled)\n",
    "test_data,test_label = data_generate(data_test_pm25_filled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>type</th>\n",
       "      <th>东四</th>\n",
       "      <th>天坛</th>\n",
       "      <th>官园</th>\n",
       "      <th>万寿西宫</th>\n",
       "      <th>奥体中心</th>\n",
       "      <th>农展馆</th>\n",
       "      <th>万柳</th>\n",
       "      <th>...</th>\n",
       "      <th>密云水库</th>\n",
       "      <th>东高村</th>\n",
       "      <th>永乐店</th>\n",
       "      <th>榆垡</th>\n",
       "      <th>琉璃河</th>\n",
       "      <th>前门</th>\n",
       "      <th>永定门内</th>\n",
       "      <th>西直门北</th>\n",
       "      <th>南三环</th>\n",
       "      <th>东四环</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, hour, type, 东四, 天坛, 官园, 万寿西宫, 奥体中心, 农展馆, 万柳, 北部新区, 植物园, 丰台花园, 云岗, 古城, 房山, 大兴, 亦庄, 通州, 顺义, 昌平, 门头沟, 平谷, 怀柔, 密云, 延庆, 定陵, 八达岭, 密云水库, 东高村, 永乐店, 榆垡, 琉璃河, 前门, 永定门内, 西直门北, 南三环, 东四环]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 38 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_pm25_filled[data_all_pm25_filled['date'] ==20140103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e06d9d6718ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtest_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mti\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmodel_now\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mti\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# 训练并测试模型\n",
    "print('training')\n",
    "models = [DecisionTreeRegressor(),RandomForestRegressor(),AdaBoostRegressor(),GradientBoostingRegressor()]\n",
    "# models = [AdaBoostRegressor(),GradientBoostingRegressor()]\n",
    "train_predict_all = []\n",
    "val_predict_all = []\n",
    "test_predict_all = []\n",
    "\n",
    "for model_now in models:\n",
    "    print(model_now)\n",
    "    start = time.time()\n",
    "    train_predict = np.zeros(train_label.shape)\n",
    "    val_predict = np.zeros(val_label.shape)\n",
    "    test_predict = np.zeros(test_label.shape)\n",
    "    \n",
    "    for ti in range(train_label.shape[1]):\n",
    "        for lo in range(train_label.shape[2]):\n",
    "            model_now.fit(train_data[:,:,lo], train_label[:,ti,lo])\n",
    "            train_predict[:,ti,lo] = model_now.predict(train_data[:,:,lo])\n",
    "            val_predict[:,ti,lo] = model_now.predict(val_data[:,:,lo])\n",
    "            test_predict[:,ti,lo] = model_now.predict(test_data[:,:,lo])\n",
    "            \n",
    "    train_predict_all.append(train_predict)\n",
    "    val_predict_all.append(val_predict)\n",
    "    test_predict_all.append(test_predict)\n",
    "    end = time.time()\n",
    "    print('training lasted: '+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评价模型性能\n",
    "\n",
    "for m in range(4):\n",
    "    print(models[m])\n",
    "    for i in range(6):\n",
    "        MAE, RMSE,PREC= Evaluation(val_label[:,i,:], val_predict_all[m][:,i,:])\n",
    "        print('time:'+str(i+1)+' '+'MAE = '+str(MAE)+' '+'RMSE = '+str(RMSE)+' '+'PREC = '+str(PREC))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
