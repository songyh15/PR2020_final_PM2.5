{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import time\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib\n",
    "matplotlib.rcParams[u'font.sans-serif'] = ['SimHei'] \n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改变此处time_in 即可改变输入时间长度\n",
    "def data_generate(data_type_filled):\n",
    "    time_in = 6\n",
    "    time_out = 6\n",
    "\n",
    "    num_sample = data_type_filled['PM2.5'].shape[0] -time_in -time_out\n",
    "    num_loc = data_type_filled['PM2.5'].shape[1] -3\n",
    "        \n",
    "    num_feature = len(data_type_filled)\n",
    "    data = []\n",
    "    label = []\n",
    "    data_filled_array = {}\n",
    "    for type_now in data_type_filled:\n",
    "        data_filled_array[type_now] = data_type_filled[type_now].iloc[:,3:].values\n",
    "        \n",
    "    start = time.time()\n",
    "    for i in range(0,num_sample):\n",
    "#         data_now = np.zeros([time_in, num_feature, num_loc])\n",
    "        data_now = np.zeros([time_in, num_feature-1, num_loc]) #舍去PM2.5 or PCA\n",
    "        feature_now = -1\n",
    "        \n",
    "\n",
    "        # 判断date是否连续\n",
    "        if data_type_filled['PM2.5'].iloc[i+time_in+time_out-1,0] - data_type_filled['PM2.5'].iloc[i,0] < 2:\n",
    "            # 判断hour是否连续\n",
    "            if data_type_filled['PM2.5'].iloc[i+time_in+time_out-1,1] == (data_type_filled['PM2.5'].iloc[i,1] + time_in+time_out-1)%24: \n",
    "                for type_now in data_type_filled:\n",
    "#                     if type_now == 'PCA': #选择只要PCA特征\n",
    "                    if type_now == 'PM2.5': #选择只要PM2.5特征\n",
    "                        feature_now = feature_now +1\n",
    "                        data_now[:,feature_now,:] = data_filled_array[type_now][i:i+time_in,:].copy()\n",
    "                    if type_now == 'PM2.5':\n",
    "                        label_now = data_filled_array[type_now][i+time_in:i+time_in+time_out,:].copy()\n",
    "                        \n",
    "#                 data_now = data_now.reshape((time_in*num_feature,num_loc))\n",
    "                data_now = data_now.reshape((time_in*(num_feature-1),num_loc)) #舍去PM2.5 or PCA\n",
    "                data.append(data_now)\n",
    "                label.append(label_now)\n",
    "        \n",
    "    end = time.time()\n",
    "#     print('data generating lasted: '+str(end-start))\n",
    "           \n",
    "    data = np.array(data)\n",
    "    label = np.array(label)\n",
    "    if label[label==0].shape[0]>0:\n",
    "        print('there is a bug')\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(loc):\n",
    "    print(loc)\n",
    "    # 读取数据\n",
    "#     data_all = pd.read_csv('../data_mix_clean/'+loc+'.csv')\n",
    "    data_all = pd.read_csv('../data_mix_clean_pca/'+loc+'.csv')\n",
    "    data_all = data_all.iloc[:,1:]\n",
    "    # 划分数据集\n",
    "    data_train = data_all[data_all['date'] < 20200000]\n",
    "    data_train = data_train[data_train['date'] > 20150000]\n",
    "    data_val = data_all[data_all['date'] > 20200000]\n",
    "    data_test = data_all[data_all['date'] < 20150000]\n",
    "    # 制作时序数据集\n",
    "    list_type = np.unique(data_all['type']).tolist()\n",
    "    data_train_type = {}\n",
    "    data_val_type = {}\n",
    "    data_test_type = {}\n",
    "    for data_type in list_type:\n",
    "        data_train_type[data_type] = data_train[data_train['type']==data_type]\n",
    "        data_val_type[data_type] = data_val[data_val['type']==data_type]\n",
    "        data_test_type[data_type] = data_test[data_test['type']==data_type]\n",
    "\n",
    "    train_data,train_label = data_generate(data_train_type)\n",
    "    val_data,val_label = data_generate(data_val_type)\n",
    "    test_data,test_label = data_generate(data_test_type)\n",
    "    \n",
    "    return [train_data,train_label,val_data,val_label,test_data,test_label,loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 并行程序，进行数据集划分\n",
    "list_loc = np.load(\"../location.npy\",allow_pickle=True)\n",
    "MultiNum = 17\n",
    "pool = Pool(processes=MultiNum)\n",
    "dataset_splited_list = pool.map(data_split,list_loc)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查数据格式\n",
    "print(dataset_splited_list[0][0].shape)\n",
    "print(dataset_splited_list[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_pass(args):\n",
    "    return train_pre(*args)\n",
    "\n",
    "def train_pre(train_data,train_label,val_data,val_label,test_data,test_label,loc, model_name):\n",
    "    # 训练模型\n",
    "    print(model_name+' '+loc)\n",
    "    train_predict = np.zeros(train_label.shape)\n",
    "    val_predict = np.zeros(val_label.shape)\n",
    "    test_predict = np.zeros(test_label.shape)\n",
    "\n",
    "    for ti in range(train_label.shape[1]):\n",
    "        # 读取模型\n",
    "        model = joblib.load('./BestModels/'+model_name+'_'+loc+'.pkl')\n",
    "        lo = 0\n",
    "        model.fit(train_data[:,:,lo], train_label[:,ti,lo])\n",
    "        train_predict[:,ti,lo] = model.predict(train_data[:,:,lo])\n",
    "        val_predict[:,ti,lo] = model.predict(val_data[:,:,lo])\n",
    "        test_predict[:,ti,lo] = model.predict(test_data[:,:,lo])\n",
    "        \n",
    "            \n",
    "    return [train_predict,val_predict,test_predict,loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改此处models，即可选择不同模型\n",
    "models = ['BaggingGBRT']\n",
    "result_models = {}\n",
    "\n",
    "# 并行程序，训练模型\n",
    "MultiNum = 17\n",
    "pool = Pool(processes=MultiNum)\n",
    "\n",
    "for model_name in models:\n",
    "    start = time.time()\n",
    "    para_list = []\n",
    "    for train_data,train_label,val_data,val_label,test_data,test_label,loc in dataset_splited_list:\n",
    "        para_list.append([train_data,train_label,val_data,val_label,test_data,test_label,loc,model_name])\n",
    "    result_pre_list = pool.map(para_pass,para_list)\n",
    "    result_models[model_name] = result_pre_list\n",
    "\n",
    "    end = time.time()\n",
    "    print('training lasted: '+str(end-start))\n",
    "pool.close() \n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义评价指标\n",
    "def Evaluation(label, predict):\n",
    "    MAE = np.mean(np.abs(label - predict))\n",
    "    RMSE = np.power(np.mean(np.power(label - predict,2)) ,0.5)\n",
    "\n",
    "    label_grade = label.copy()\n",
    "    label_grade[label_grade <= 35] = 1\n",
    "    label_grade[label_grade > 250] = 6\n",
    "    label_grade[label_grade > 150] = 5\n",
    "    label_grade[label_grade > 115] = 4\n",
    "    label_grade[label_grade > 75] = 3\n",
    "    label_grade[label_grade > 35] = 2\n",
    "    \n",
    "    predict_grade = predict.copy()\n",
    "    predict_grade[predict_grade <= 35] = 1\n",
    "    predict_grade[predict_grade > 250] = 6\n",
    "    predict_grade[predict_grade > 150] = 5\n",
    "    predict_grade[predict_grade > 115] = 4\n",
    "    predict_grade[predict_grade > 75] = 3\n",
    "    predict_grade[predict_grade > 35] = 2\n",
    "    \n",
    "    Accu = accuracy_score(label_grade,predict_grade)\n",
    "    return MAE,RMSE,Accu\n",
    "\n",
    "def Evaluation_PR(label, predict):\n",
    "\n",
    "    label_grade = label.copy()\n",
    "    label_grade[label_grade <= 35] = 1\n",
    "    label_grade[label_grade > 250] = 6\n",
    "    label_grade[label_grade > 150] = 5\n",
    "    label_grade[label_grade > 115] = 4\n",
    "    label_grade[label_grade > 75] = 3\n",
    "    label_grade[label_grade > 35] = 2\n",
    "    \n",
    "    predict_grade = predict.copy()\n",
    "    predict_grade[predict_grade <= 35] = 1\n",
    "    predict_grade[predict_grade > 250] = 6\n",
    "    predict_grade[predict_grade > 150] = 5\n",
    "    predict_grade[predict_grade > 115] = 4\n",
    "    predict_grade[predict_grade > 75] = 3\n",
    "    predict_grade[predict_grade > 35] = 2\n",
    "    \n",
    "    Prec = precision_score(label_grade, predict_grade, average=None)\n",
    "    Rec = recall_score(label_grade, predict_grade, average=None)\n",
    "    return Prec,Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算评价指标\n",
    "for model_name in models:\n",
    "    MAE = np.zeros([3,len(result_models[model_name]),6])\n",
    "    RMSE = np.zeros([3,len(result_models[model_name]),6])\n",
    "    PREC = np.zeros([3,len(result_models[model_name]),6])\n",
    "    \n",
    "    Precision = np.zeros([3,len(result_models[model_name]),6,6])\n",
    "    Recall = np.zeros([3,len(result_models[model_name]),6,6])\n",
    "    \n",
    "    count_correct = 0\n",
    "    count_all = 0\n",
    "    count_correct_1 = 0\n",
    "    count_all_1 = 0\n",
    "    for ti in range(6):\n",
    "        for train_predict,val_predict,test_predict,loc_pre in result_models[model_name]:\n",
    "            idx_loc = list_loc.tolist().index(loc_pre)\n",
    "            for _,train_label,_,val_label,_,test_label,loc_label in dataset_splited_list:\n",
    "                if loc_pre == loc_label:\n",
    "                    MAE[0,idx_loc,ti], RMSE[0,idx_loc,ti],PREC[0,idx_loc,ti]= Evaluation(train_label[:,ti,:],train_predict[:,ti,:])\n",
    "                    MAE[1,idx_loc,ti], RMSE[1,idx_loc,ti],PREC[1,idx_loc,ti]= Evaluation(val_label[:,ti,:],val_predict[:,ti,:])\n",
    "                    MAE[2,idx_loc,ti], RMSE[2,idx_loc,ti],PREC[2,idx_loc,ti]= Evaluation(test_label[:,ti,:],test_predict[:,ti,:])\n",
    "\n",
    "                    Precision[0,idx_loc,ti,:],Recall[0,idx_loc,ti,:] = Evaluation_PR(train_label[:,ti,:],train_predict[:,ti,:])\n",
    "#                     Precision[1,idx_loc,ti,:],Recall[1,idx_loc,ti,:] = Evaluation_PR(val_label[:,ti,:],val_predict[:,ti,:])\n",
    "                    Precision[2,idx_loc,ti,:],Recall[2,idx_loc,ti,:] = Evaluation_PR(test_label[:,ti,:],test_predict[:,ti,:])\n",
    "\n",
    "                    if ti == 0:\n",
    "                        count_all_1 = count_all_1 + val_label[:,ti,:].shape[0]\n",
    "                        count_correct_1 = count_correct_1 + PREC[1,idx_loc,ti]*val_label[:,ti,:].shape[0]\n",
    "\n",
    "                    count_all = count_all + val_label[:,ti,:].shape[0]\n",
    "                    count_correct = count_correct + PREC[1,idx_loc,ti]*val_label[:,ti,:].shape[0]\n",
    "                    \n",
    "#     np.save('../results/4_final_accuracy_'+model_name+'.npy',PREC)\n",
    "#     np.save('../results/4_final_precision_'+model_name+'.npy',Precision)\n",
    "#     np.save('../results/4_final_recall_'+model_name+'.npy',Recall)\n",
    "                    \n",
    "print('one later hour: ' + str(count_correct_1 / count_all_1))                   \n",
    "print('all later hour: ' + str(count_correct / count_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画图\n",
    "fig = plt.figure(figsize = (15,9))\n",
    "plt.rcParams['figure.dpi'] = 200 #分辨率\n",
    "plt.plot(list_loc, # x轴数据\n",
    "         PREC[2,:,:], # y轴数据\n",
    "         linestyle = '-', # 折线类型\n",
    "         linewidth = 2, # 折线宽度\n",
    "#          color = 'steelblue', # 折线颜色\n",
    "         marker = 'o', # 点的形状\n",
    "         markersize = 6, # 点的大小\n",
    "#          markeredgecolor='black', # 点的边框色\n",
    "         markerfacecolor='brown') # 点的填充色\n",
    "plt.title('BaggingGBRT PM2.5等级预测情况')\n",
    "plt.xlabel('地点')\n",
    "plt.ylabel('等级预测准确率')\n",
    "plt.tick_params(top = 'off', right = 'off')\n",
    "fig.autofmt_xdate(rotation = 45)\n",
    "# 设置图例\n",
    "plt.legend([1,2,3,4,5,6])\n",
    "# plt.legend([1,2,3,4,5,6],bbox_to_anchor=(1.01,0.8))\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
