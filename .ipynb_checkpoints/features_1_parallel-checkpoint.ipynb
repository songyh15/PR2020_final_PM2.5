{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def data_generate(data_type_filled):\n",
    "    time_in = 12\n",
    "    time_out = 6\n",
    "    num_sample = data_type_filled['PM2.5'].shape[0] -time_in -time_out\n",
    "    num_loc = data_type_filled['PM2.5'].shape[1] -3\n",
    "    num_feature = len(data_type_filled)\n",
    "    data = []\n",
    "    label = []\n",
    "    data_filled_array = {}\n",
    "    for type_now in data_type_filled:\n",
    "        data_filled_array[type_now] = data_type_filled[type_now].iloc[:,3:].values\n",
    "        \n",
    "    start = time.time()\n",
    "    for i in range(0,num_sample):\n",
    "        data_now = np.zeros([time_in, num_feature, num_loc])\n",
    "        label_now = np.zeros([time_out,num_loc])\n",
    "        feature_now = -1\n",
    "        for type_now in data_type_filled:\n",
    "            feature_now = feature_now +1\n",
    "            if data_type_filled[type_now].iloc[i+time_in+time_out-1,0] < 20170708 :\n",
    "                data_now[:,feature_now,:] = data_filled_array[type_now][i:i+time_in,:]\n",
    "                if type_now == 'PM2.5':\n",
    "                    label_now = data_filled_array[type_now][i+time_in:i+time_in+time_out,:]\n",
    "            elif data_type_filled[type_now].iloc[i,0] > 20170708 :\n",
    "                data_now[:,feature_now,:] = data_filled_array[type_now][i:i+time_in,:]\n",
    "                if type_now == 'PM2.5':\n",
    "                    label_now = data_filled_array[type_now][i+time_in:i+time_in+time_out,:]\n",
    "        \n",
    "        data_now = data_now.reshape((time_in*num_feature,num_loc))\n",
    "        data.append(data_now)\n",
    "        label.append(label_now)\n",
    "        \n",
    "    end = time.time()\n",
    "#     print('data generating lasted: '+str(end-start))\n",
    "                \n",
    "    data = np.array(data)\n",
    "    label = np.array(label)\n",
    "    return data, label\n",
    "\n",
    "def Evaluation(label, predict):\n",
    "    MAE = np.mean(np.abs(label - predict))\n",
    "    RMSE = np.power(np.mean(np.power(label - predict,2)) ,0.5)\n",
    "\n",
    "    label_grade = label.copy()\n",
    "    label_grade[label_grade < 35] = 1\n",
    "    label_grade[label_grade > 250] = 6\n",
    "    label_grade[label_grade > 150] = 5\n",
    "    label_grade[label_grade > 115] = 4\n",
    "    label_grade[label_grade > 75] = 3\n",
    "    label_grade[label_grade > 35] = 2\n",
    "    \n",
    "    predict_grade = predict.copy()\n",
    "    predict_grade[predict_grade < 35] = 1\n",
    "    predict_grade[predict_grade > 250] = 6\n",
    "    predict_grade[predict_grade > 150] = 5\n",
    "    predict_grade[predict_grade > 115] = 4\n",
    "    predict_grade[predict_grade > 75] = 3\n",
    "    predict_grade[predict_grade > 35] = 2\n",
    "    \n",
    "    res = np.zeros(label_grade.shape)\n",
    "    res[label_grade == predict_grade] = 1\n",
    "    num_cor = res.sum()\n",
    "    num_all = res.shape[0] * res.shape[1]\n",
    "    prec = num_cor/num_all\n",
    "    return MAE,RMSE,prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/syh/ENTER/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data_all = pd.read_csv(\"data_all.csv\")\n",
    "# data_extra = pd.read_csv(\"data_extra.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删去无用的前三列\n",
    "data_all = data_all.iloc[:,3:]\n",
    "# data_extra = data_extra.iloc[:,3:]\n",
    "\n",
    "# 删去缺失了一半PM2.5数据的植物园\n",
    "data_all = data_all.drop(columns=['植物园'])\n",
    "\n",
    "# 删去20170702-20170708\n",
    "data_all = data_all.drop(index= range(148393,148456))\n",
    "\n",
    "# 选取PM2.5数据\n",
    "data_all = data_all[data_all['type']=='PM2.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>南三环</td>\n",
       "      <td>4894</td>\n",
       "      <td>0.090422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>琉璃河</td>\n",
       "      <td>4727</td>\n",
       "      <td>0.087336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>东四环</td>\n",
       "      <td>4265</td>\n",
       "      <td>0.078801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>八达岭</td>\n",
       "      <td>4038</td>\n",
       "      <td>0.074606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>榆垡</td>\n",
       "      <td>3692</td>\n",
       "      <td>0.068214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>通州</td>\n",
       "      <td>3085</td>\n",
       "      <td>0.056999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>前门</td>\n",
       "      <td>2988</td>\n",
       "      <td>0.055207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>东高村</td>\n",
       "      <td>2701</td>\n",
       "      <td>0.049904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>密云水库</td>\n",
       "      <td>2572</td>\n",
       "      <td>0.047521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>西直门北</td>\n",
       "      <td>2474</td>\n",
       "      <td>0.045710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>北部新区</td>\n",
       "      <td>2400</td>\n",
       "      <td>0.044343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>永乐店</td>\n",
       "      <td>2120</td>\n",
       "      <td>0.039169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>永定门内</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.037045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>丰台花园</td>\n",
       "      <td>1873</td>\n",
       "      <td>0.034606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>大兴</td>\n",
       "      <td>1830</td>\n",
       "      <td>0.033811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>怀柔</td>\n",
       "      <td>1737</td>\n",
       "      <td>0.032093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>延庆</td>\n",
       "      <td>1696</td>\n",
       "      <td>0.031335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>门头沟</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.031040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>天坛</td>\n",
       "      <td>1638</td>\n",
       "      <td>0.030264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>万寿西宫</td>\n",
       "      <td>1570</td>\n",
       "      <td>0.029007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>云岗</td>\n",
       "      <td>1568</td>\n",
       "      <td>0.028971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>平谷</td>\n",
       "      <td>1567</td>\n",
       "      <td>0.028952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>奥体中心</td>\n",
       "      <td>1551</td>\n",
       "      <td>0.028656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>昌平</td>\n",
       "      <td>1534</td>\n",
       "      <td>0.028342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>亦庄</td>\n",
       "      <td>1449</td>\n",
       "      <td>0.026772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>房山</td>\n",
       "      <td>1438</td>\n",
       "      <td>0.026569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>顺义</td>\n",
       "      <td>1437</td>\n",
       "      <td>0.026550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>古城</td>\n",
       "      <td>1428</td>\n",
       "      <td>0.026384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>农展馆</td>\n",
       "      <td>1411</td>\n",
       "      <td>0.026070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>东四</td>\n",
       "      <td>1405</td>\n",
       "      <td>0.025959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>密云</td>\n",
       "      <td>1299</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>官园</td>\n",
       "      <td>1296</td>\n",
       "      <td>0.023945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>定陵</td>\n",
       "      <td>1227</td>\n",
       "      <td>0.022670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>万柳</td>\n",
       "      <td>1226</td>\n",
       "      <td>0.022652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>type</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hour</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>date</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count     ratio\n",
       "南三环    4894  0.090422\n",
       "琉璃河    4727  0.087336\n",
       "东四环    4265  0.078801\n",
       "八达岭    4038  0.074606\n",
       "榆垡     3692  0.068214\n",
       "通州     3085  0.056999\n",
       "前门     2988  0.055207\n",
       "东高村    2701  0.049904\n",
       "密云水库   2572  0.047521\n",
       "西直门北   2474  0.045710\n",
       "北部新区   2400  0.044343\n",
       "永乐店    2120  0.039169\n",
       "永定门内   2005  0.037045\n",
       "丰台花园   1873  0.034606\n",
       "大兴     1830  0.033811\n",
       "怀柔     1737  0.032093\n",
       "延庆     1696  0.031335\n",
       "门头沟    1680  0.031040\n",
       "天坛     1638  0.030264\n",
       "万寿西宫   1570  0.029007\n",
       "云岗     1568  0.028971\n",
       "平谷     1567  0.028952\n",
       "奥体中心   1551  0.028656\n",
       "昌平     1534  0.028342\n",
       "亦庄     1449  0.026772\n",
       "房山     1438  0.026569\n",
       "顺义     1437  0.026550\n",
       "古城     1428  0.026384\n",
       "农展馆    1411  0.026070\n",
       "东四     1405  0.025959\n",
       "密云     1299  0.024000\n",
       "官园     1296  0.023945\n",
       "定陵     1227  0.022670\n",
       "万柳     1226  0.022652\n",
       "type      0  0.000000\n",
       "hour      0  0.000000\n",
       "date      0  0.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看全体数据缺失情况\n",
    "na_count = data_all.isnull().sum().sort_values(ascending=False)\n",
    "na_rate = na_count / len(data_all)\n",
    "na_data = pd.concat([na_count,na_rate],axis=1,keys=['count','ratio'])\n",
    "na_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "data_train = data_all[data_all['date'] < 20200000]\n",
    "data_train = data_train[data_train['date'] > 20150000]\n",
    "data_val = data_all[data_all['date'] > 20200000]\n",
    "data_test = data_all[data_all['date'] < 20150000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all_type = {}\n",
    "# for data_type in data_all['type'][0:5]:\n",
    "#     data_all_type[data_type] = data_all[data_all['type']==data_type]\n",
    "# for data_type in data_extra['type'][0:7]:\n",
    "#     data_all_type[data_type] = data_extra[data_extra['type']==data_type]\n",
    "\n",
    "data_train_type = {}\n",
    "for data_type in data_train['type'][0:5]:\n",
    "    data_train_type[data_type] = data_train[data_train['type']==data_type]\n",
    "data_val_type = {}\n",
    "for data_type in data_val['type'][0:5]:\n",
    "    data_val_type[data_type] = data_val[data_val['type']==data_type]\n",
    "data_test_type = {}\n",
    "for data_type in data_test['type'][0:5]:\n",
    "    data_test_type[data_type] = data_test[data_test['type']==data_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for type_now in data_all_type:\n",
    "#     data_all_type[type_now] = data_all_type[type_now].fillna(method='ffill')\n",
    "#     data_all_type[type_now] = data_all_type[type_now].fillna(method='bfill')\n",
    "for type_now in data_train_type:\n",
    "    data_train_type[type_now] = data_train_type[type_now].fillna(method='ffill')\n",
    "    data_train_type[type_now] = data_train_type[type_now].fillna(method='bfill')\n",
    "for type_now in data_val_type:\n",
    "    data_val_type[type_now] = data_val_type[type_now].fillna(method='ffill')\n",
    "    data_val_type[type_now] = data_val_type[type_now].fillna(method='bfill')\n",
    "for type_now in data_test_type:\n",
    "    data_test_type[type_now] = data_test_type[type_now].fillna(method='ffill')\n",
    "    data_test_type[type_now] = data_test_type[type_now].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "0\n",
      "val\n",
      "0\n",
      "test\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 查看数据缺失情况\n",
    "print('train')\n",
    "for type_now in data_train_type:\n",
    "    df = data_train_type[type_now] \n",
    "    na_count = df.isnull().sum().sort_values(ascending=False)\n",
    "    na_rate = na_count / len(df)\n",
    "    na_data = pd.concat([na_count,na_rate],axis=1,keys=['count','ratio'])\n",
    "    print(na_data['count'].max())\n",
    "print('val')\n",
    "for type_now in data_val_type:\n",
    "    df = data_val_type[type_now] \n",
    "    na_count = df.isnull().sum().sort_values(ascending=False)\n",
    "    na_rate = na_count / len(df)\n",
    "    na_data = pd.concat([na_count,na_rate],axis=1,keys=['count','ratio'])\n",
    "    print(na_data['count'].max())\n",
    "print('test')\n",
    "for type_now in data_test_type:\n",
    "    df = data_test_type[type_now] \n",
    "    na_count = df.isnull().sum().sort_values(ascending=False)\n",
    "    na_rate = na_count / len(df)\n",
    "    na_data = pd.concat([na_count,na_rate],axis=1,keys=['count','ratio'])\n",
    "    print(na_data['count'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作时序数据集\n",
    "train_data,train_label = data_generate(data_train_type)\n",
    "val_data,val_label = data_generate(data_val_type)\n",
    "test_data,test_label = data_generate(data_test_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_pass(args):\n",
    "    return model_fitting(*args)\n",
    "\n",
    "def model_fitting(model,train_data,train_label,ti,lo):\n",
    "    model.fit(train_data[:,:,lo], train_label[:,ti,lo])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=50, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best')\n",
      "training lasted: 31.027734756469727\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=50,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n",
      "training lasted: 152.98888301849365\n",
      "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse',\n",
      "                                                       max_depth=50,\n",
      "                                                       max_features=None,\n",
      "                                                       max_leaf_nodes=None,\n",
      "                                                       min_impurity_decrease=0.0,\n",
      "                                                       min_impurity_split=None,\n",
      "                                                       min_samples_leaf=1,\n",
      "                                                       min_samples_split=2,\n",
      "                                                       min_weight_fraction_leaf=0.0,\n",
      "                                                       presort=False,\n",
      "                                                       random_state=None,\n",
      "                                                       splitter='best'),\n",
      "                  learning_rate=1.0, loss='linear', n_estimators=10,\n",
      "                  random_state=None)\n",
      "training lasted: 208.82601642608643\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=50,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "training lasted: 6012.520257234573\n"
     ]
    }
   ],
   "source": [
    "# 训练并测试模型\n",
    "print('training')\n",
    "DT = DecisionTreeRegressor(max_depth = 50)\n",
    "RF = RandomForestRegressor(n_estimators=10,max_depth = 50)\n",
    "Ada_DT = AdaBoostRegressor(base_estimator = DecisionTreeRegressor(max_depth=50),n_estimators=10)\n",
    "GBDT = GradientBoostingRegressor(n_estimators=10,max_depth = 50)\n",
    "models = [DT,RF,Ada_DT,GBDT]\n",
    "train_predict_all = []\n",
    "val_predict_all = []\n",
    "test_predict_all = []\n",
    "\n",
    "MultiNum = 16\n",
    "pool = Pool(processes=MultiNum)\n",
    "\n",
    "for model_now in models:\n",
    "    print(model_now)\n",
    "    start = time.time()\n",
    "    train_predict = np.zeros(train_label.shape)\n",
    "    val_predict = np.zeros(val_label.shape)\n",
    "    test_predict = np.zeros(test_label.shape)\n",
    "    \n",
    "    num_time = train_label.shape[1]\n",
    "    num_loc = train_label.shape[2]\n",
    "    \n",
    "    para_model = [model_now]*num_loc*num_time\n",
    "    para_train_data = [train_data]*num_loc*num_time\n",
    "    para_train_label = [train_label]*num_loc*num_time\n",
    "    para_loc = [lo for lo in range(num_loc)]*num_time\n",
    "\n",
    "# 时间和空间都并行\n",
    "    para_ti = [ti for ti in range(num_time) for lo in range(num_loc)]\n",
    "    para_list = list(zip(para_model, para_train_data,para_train_label,para_ti,para_loc))\n",
    "    model_fitted_list = pool.map(para_pass,para_list)\n",
    "    idex = 0\n",
    "    for ti in range(num_time):\n",
    "        for lo in range(num_loc):\n",
    "            model_fitted = model_fitted_list[idex]\n",
    "            train_predict[:,ti,lo] = model_fitted.predict(train_data[:,:,lo])\n",
    "            val_predict[:,ti,lo] = model_fitted.predict(val_data[:,:,lo])\n",
    "            test_predict[:,ti,lo] = model_fitted.predict(test_data[:,:,lo])\n",
    "            idex = idex + 1\n",
    "\n",
    "# 时间串行，空间并行\n",
    "#     for ti in range(num_time):\n",
    "#         para_ti = [ti]*num_loc\n",
    "#         para_list = list(zip(para_model, para_train_data,para_train_label,para_ti,para_loc))\n",
    "#         model_fitted_list = pool.map(para_pass,para_list)\n",
    "#         for lo in range(num_loc):\n",
    "#             model_fitted = model_fitted_list[lo]\n",
    "#             train_predict[:,ti,lo] = model_fitted.predict(train_data[:,:,lo])\n",
    "#             val_predict[:,ti,lo] = model_fitted.predict(val_data[:,:,lo])\n",
    "#             test_predict[:,ti,lo] = model_fitted.predict(test_data[:,:,lo])\n",
    "            \n",
    "    train_predict_all.append(train_predict)\n",
    "    val_predict_all.append(val_predict)\n",
    "    test_predict_all.append(test_predict)\n",
    "    end = time.time()\n",
    "    print('training lasted: '+str(end-start))\n",
    "        \n",
    "pool.close()\n",
    "pool.join()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(criterion='mse', max_depth=50, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best')\n",
      "train error\n",
      "time:1 MAE = 10.07142668707161 RMSE = 23.013029256331066 PREC = 0.8207554866606837\n",
      "time:2 MAE = 14.87082011233463 RMSE = 38.61957068162249 PREC = 0.7589865631952962\n",
      "time:3 MAE = 20.039040092577565 RMSE = 41.71598851841619 PREC = 0.6930823341349046\n",
      "time:4 MAE = 22.278811572321437 RMSE = 50.48133204545503 PREC = 0.6763620373276841\n",
      "time:5 MAE = 26.35926174703123 RMSE = 52.74363035123608 PREC = 0.6298752839954478\n",
      "time:6 MAE = 27.23622187762292 RMSE = 58.38047471889756 PREC = 0.6308653788979801\n",
      "val error\n",
      "time:1 MAE = 9.988138732149833 RMSE = 20.49556287403834 PREC = 0.7999961262081389\n",
      "time:2 MAE = 15.454234879498879 RMSE = 28.80427264692186 PREC = 0.7118673613666737\n",
      "time:3 MAE = 19.918889706683846 RMSE = 35.577221373501956 PREC = 0.6460128997268977\n",
      "time:4 MAE = 23.205319342157132 RMSE = 39.77673875347003 PREC = 0.6047279629665498\n",
      "time:5 MAE = 26.71782418255894 RMSE = 45.05935306385868 PREC = 0.5654283445350481\n",
      "time:6 MAE = 28.768608088237865 RMSE = 47.65407634377574 PREC = 0.5415076797923648\n",
      "test error\n",
      "time:1 MAE = 45.03868492565832 RMSE = 3667.1992364453686 PREC = 0.7179046801202232\n",
      "time:2 MAE = 55.091254505439174 RMSE = 3665.472481167545 PREC = 0.6044058781977589\n",
      "time:3 MAE = 63.49438052298855 RMSE = 3667.8388740622163 PREC = 0.5257275031510131\n",
      "time:4 MAE = 69.28591542924522 RMSE = 3666.77858540671 PREC = 0.4743452125375698\n",
      "time:5 MAE = 74.74991681649648 RMSE = 3666.278180142646 PREC = 0.4361521627723376\n",
      "time:6 MAE = 78.75060253850086 RMSE = 3668.126376899624 PREC = 0.4073809886563526\n"
     ]
    }
   ],
   "source": [
    "# 模型DT平行性能\n",
    "for m in range(len(models)):\n",
    "    print(models[m])\n",
    "    print('train error')\n",
    "    for i in range(6):\n",
    "        MAE, RMSE,PREC= Evaluation(train_label[:,i,:], train_predict_all[m][:,i,:])\n",
    "        print('time:'+str(i+1)+' '+'MAE = '+str(MAE)+' '+'RMSE = '+str(RMSE)+' '+'PREC = '+str(PREC))\n",
    "    print('val error')\n",
    "    for i in range(6):\n",
    "        MAE, RMSE,PREC= Evaluation(val_label[:,i,:], val_predict_all[m][:,i,:])\n",
    "        print('time:'+str(i+1)+' '+'MAE = '+str(MAE)+' '+'RMSE = '+str(RMSE)+' '+'PREC = '+str(PREC))\n",
    "    print('test error') \n",
    "    for i in range(6):\n",
    "        MAE, RMSE,PREC= Evaluation(test_label[:,i,:], test_predict_all[m][:,i,:])\n",
    "        print('time:'+str(i+1)+' '+'MAE = '+str(MAE)+' '+'RMSE = '+str(RMSE)+' '+'PREC = '+str(PREC))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=50,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n",
      "time:1 MAE = 3.769045078588411 RMSE = 9.10315268164406 PREC = 0.9247216740900738\n",
      "time:2 MAE = 5.860892048865113 RMSE = 13.167396292827702 PREC = 0.8863423598829033\n",
      "time:3 MAE = 7.4616373732417935 RMSE = 15.870358153341577 PREC = 0.8571891814155315\n",
      "time:4 MAE = 8.757769896245817 RMSE = 18.23490217002666 PREC = 0.8340851232709638\n",
      "time:5 MAE = 9.860976007698019 RMSE = 19.958764613596486 PREC = 0.8144754363815626\n",
      "time:6 MAE = 10.793526760250145 RMSE = 21.34063815880051 PREC = 0.798273694865473\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=50,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n",
      "time:1 MAE = 6.853049761131554 RMSE = 12.990907284416377 PREC = 0.8586453349861511\n",
      "time:2 MAE = 10.790194613070776 RMSE = 19.542097514189678 PREC = 0.785943946231769\n",
      "time:3 MAE = 13.974788723471326 RMSE = 24.523800926566913 PREC = 0.7273334753723683\n",
      "time:4 MAE = 16.616888467475857 RMSE = 27.851780974683276 PREC = 0.6834240446260822\n",
      "time:5 MAE = 18.87161650580423 RMSE = 30.872168645652295 PREC = 0.64808537837262\n",
      "time:6 MAE = 20.770065118378145 RMSE = 33.28912467057384 PREC = 0.6196130081930697\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=50,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n",
      "time:1 MAE = 40.00294097472856 RMSE = 3664.099522795849 PREC = 0.7862989792102384\n",
      "time:2 MAE = 47.69337590078086 RMSE = 3664.8964990876498 PREC = 0.6798813002950179\n",
      "time:3 MAE = 53.73516671145594 RMSE = 3665.2073683048297 PREC = 0.6036752586600922\n",
      "time:4 MAE = 58.61991373775494 RMSE = 3665.728691310364 PREC = 0.5470158866466295\n",
      "time:5 MAE = 62.715358687832136 RMSE = 3666.0630200519963 PREC = 0.5046538040693085\n",
      "time:6 MAE = 66.17708740018378 RMSE = 3666.4420705241514 PREC = 0.4645285945788723\n"
     ]
    }
   ],
   "source": [
    "# 模型RT性能\n",
    "for m in range(len(models)):\n",
    "    print(models[m])\n",
    "    print('train error')\n",
    "    for i in range(6):\n",
    "        MAE, RMSE,PREC= Evaluation(train_label[:,i,:], train_predict_all[m][:,i,:])\n",
    "        print('time:'+str(i+1)+' '+'MAE = '+str(MAE)+' '+'RMSE = '+str(RMSE)+' '+'PREC = '+str(PREC))\n",
    "    print('val error')\n",
    "    for i in range(6):\n",
    "        MAE, RMSE,PREC= Evaluation(val_label[:,i,:], val_predict_all[m][:,i,:])\n",
    "        print('time:'+str(i+1)+' '+'MAE = '+str(MAE)+' '+'RMSE = '+str(RMSE)+' '+'PREC = '+str(PREC))\n",
    "    print('test error') \n",
    "    for i in range(6):\n",
    "        MAE, RMSE,PREC= Evaluation(test_label[:,i,:], test_predict_all[m][:,i,:])\n",
    "        print('time:'+str(i+1)+' '+'MAE = '+str(MAE)+' '+'RMSE = '+str(RMSE)+' '+'PREC = '+str(PREC))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse',\n",
      "                                                       max_depth=50,\n",
      "                                                       max_features=None,\n",
      "                                                       max_leaf_nodes=None,\n",
      "                                                       min_impurity_decrease=0.0,\n",
      "                                                       min_impurity_split=None,\n",
      "                                                       min_samples_leaf=1,\n",
      "                                                       min_samples_split=2,\n",
      "                                                       min_weight_fraction_leaf=0.0,\n",
      "                                                       presort=False,\n",
      "                                                       random_state=None,\n",
      "                                                       splitter='best'),\n",
      "                  learning_rate=1.0, loss='linear', n_estimators=10,\n",
      "                  random_state=None)\n",
      "train error\n",
      "time:1 MAE = 0.8839825645457966 RMSE = 6.849832323135521 PREC = 0.9838701648176137\n",
      "time:2 MAE = 1.0560965977185461 RMSE = 8.700289908453316 PREC = 0.9809800833283783\n",
      "time:3 MAE = 1.2004449777226578 RMSE = 11.63553809415592 PREC = 0.9786154712008219\n",
      "time:4 MAE = 1.2855083305732187 RMSE = 10.60382762315618 PREC = 0.9769554028621487\n",
      "time:5 MAE = 1.356366971808038 RMSE = 11.122447809807914 PREC = 0.9754916941270502\n",
      "time:6 MAE = 1.4390402018316633 RMSE = 12.12855443546429 PREC = 0.974218122332033\n",
      "val error\n",
      "time:1 MAE = 6.876841040891165 RMSE = 13.09380139765552 PREC = 0.8542098433051192\n",
      "time:2 MAE = 10.702489498858055 RMSE = 19.77376041344994 PREC = 0.7807336961785043\n",
      "time:3 MAE = 13.818176609898822 RMSE = 24.509270288144677 PREC = 0.7269073582676403\n",
      "time:4 MAE = 16.609935378589867 RMSE = 28.679098603712855 PREC = 0.6817873675647408\n",
      "time:5 MAE = 18.89501299834278 RMSE = 31.803146612773897 PREC = 0.6477270526254625\n",
      "time:6 MAE = 20.899621112745383 RMSE = 34.801641332652935 PREC = 0.6192934203645238\n",
      "test error\n",
      "time:1 MAE = 40.10429355247786 RMSE = 3664.5832329528503 PREC = 0.7851528414520976\n",
      "time:2 MAE = 47.68692213648421 RMSE = 3665.0974667710534 PREC = 0.6815052840067037\n",
      "time:3 MAE = 53.875204033343714 RMSE = 3665.4461009294023 PREC = 0.6092085762960706\n",
      "time:4 MAE = 59.09116868215181 RMSE = 3665.502448494945 PREC = 0.5514273050873281\n",
      "time:5 MAE = 63.298472807929414 RMSE = 3666.3019679110203 PREC = 0.5100624662391446\n",
      "time:6 MAE = 67.12610429296278 RMSE = 3666.3986069712787 PREC = 0.47516932367484316\n"
     ]
    }
   ],
   "source": [
    "# 模型Ada_DT性能\n",
    "for m in range(len(models)):\n",
    "    print(models[m])\n",
    "    print('train error')\n",
    "    for i in range(6):\n",
    "        MAE, RMSE,PREC= Evaluation(train_label[:,i,:], train_predict_all[m][:,i,:])\n",
    "        print('time:'+str(i+1)+' '+'MAE = '+str(MAE)+' '+'RMSE = '+str(RMSE)+' '+'PREC = '+str(PREC))\n",
    "    print('val error')\n",
    "    for i in range(6):\n",
    "        MAE, RMSE,PREC= Evaluation(val_label[:,i,:], val_predict_all[m][:,i,:])\n",
    "        print('time:'+str(i+1)+' '+'MAE = '+str(MAE)+' '+'RMSE = '+str(RMSE)+' '+'PREC = '+str(PREC))\n",
    "    print('test error') \n",
    "    for i in range(6):\n",
    "        MAE, RMSE,PREC= Evaluation(test_label[:,i,:], test_predict_all[m][:,i,:])\n",
    "        print('time:'+str(i+1)+' '+'MAE = '+str(MAE)+' '+'RMSE = '+str(RMSE)+' '+'PREC = '+str(PREC))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型GBDT性能\n",
    "for m in range(len(models)):\n",
    "    print(models[m])\n",
    "    print('train error')\n",
    "    for i in range(6):\n",
    "        MAE, RMSE,PREC= Evaluation(train_label[:,i,:], train_predict_all[m][:,i,:])\n",
    "        print('time:'+str(i+1)+' '+'MAE = '+str(MAE)+' '+'RMSE = '+str(RMSE)+' '+'PREC = '+str(PREC))\n",
    "    print('val error')\n",
    "    for i in range(6):\n",
    "        MAE, RMSE,PREC= Evaluation(val_label[:,i,:], val_predict_all[m][:,i,:])\n",
    "        print('time:'+str(i+1)+' '+'MAE = '+str(MAE)+' '+'RMSE = '+str(RMSE)+' '+'PREC = '+str(PREC))\n",
    "    print('test error') \n",
    "    for i in range(6):\n",
    "        MAE, RMSE,PREC= Evaluation(test_label[:,i,:], test_predict_all[m][:,i,:])\n",
    "        print('time:'+str(i+1)+' '+'MAE = '+str(MAE)+' '+'RMSE = '+str(RMSE)+' '+'PREC = '+str(PREC))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
